% \begin{abstract}

Semantic heterogeneity remains a fundamental barrier to data integration: independently authored tables encode equivalent concepts under incompatible schemas, headers, and naming conventions. Semantic annotation, i.e., mapping tabular data to a controlled ontology, is essential for transforming isolated tabular artifacts into interoperable, queryable assets. Traditional approaches based on rules, string matching, or supervised machine learning suffer from rigidity, limited generalization, and dependence on costly labeled data. Large Language Models (LLMs) offer a promising alternative due to their world knowledge and zero-shot reasoning capabilities. However, naive application of LLMs to semantic annotation introduces critical challenges: hallucination of non-existent ontology classes, inconsistent outputs across repeated queries, and lack of structural guarantees with respect to the target ontology. This thesis presents the design, implementation, and evaluation of an end-to-end platform for ontology-driven semantic annotation that addresses these challenges. The platform recasts LLMs from open-ended generators into bounded decision engines that perform constrained navigation over an ontology modeled as a Directed Acyclic Graph (DAG). A Breadth-First Search (BFS) traversal guides the annotation process from coarse to fine-grained concepts, while Chain-of-Thought (CoT) prompting encourages explicit reasoning at each decision step. An Ensemble Decision Making (EDM) mechanism aggregates judgments from multiple LLM agents to reduce variance and improve robustness. The platform and algorithm are evaluated on a real-world benchmark from the energy domain comprising 47 tables with 431 columns, and a ontology (Building Energy Ontology) with 602 classes. The best configuration achieves 38.16\% path-level F$_1$, with CoT prompting providing a 6.35 percentage point improvement over direct prompting. A systematic cost-accuracy analysis identifies Pareto-efficient configurations and provides deployment guidelines for different operational constraints. The main contributions include a modular four-layer architecture, a multi-provider LLM abstraction supporting both commercial APIs and local models, and comprehensive traceability for reproducible experimentation.

% \end{abstract}
